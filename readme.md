# 3D Gaussian Splatting with Nvidia Warp

3DGS implementation in NVIDIA Warp â€” clean, minimal, and runs on CPU or GPU.

![The training video](examples/example_lego_train.gif)

## Why This Implementation?

### âœ… CPU & GPU with Zero Hassle

Built with NVIDIA Warp, the same code runs seamlessly on both CPU and GPU â€” no need to deal with CUDA setup, driver issues, or device-specific kernels. Just flip one config line.

### ðŸ§  Learn Modern Graphics the Easy Way

Explore core concepts in differentiable rendering and parallel graphics programming â€” no need for expensive GPUs or thousands of lines of boilerplate.

### ðŸ“¦ Minimalist & Educational

This isnâ€™t another massive codebase. Itâ€™s a clean, hackable implementation built for clarity â€” perfect for study, prototyping, or teaching yourself how Gaussian Splatting works.

## Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/guoriyue/3dgs-warp-scratch.git
cd 3dgs-warp-scratch

# Install dependencies
pip install warp-lang numpy matplotlib imageio tqdm plyfile torch
```

### Download Example Data

```bash
# Download the Lego dataset
bash download_example_data.sh
```


### Rendering

```bash
# Render 3 Gaussian points â€“ a minimalist example
python render.py
```
You should see 3 Gaussian points like ![this](examples/example_render.png)

### Training

```bash
# Train on Lego dataset (CPU by default)
# For GPU training, change DEVICE in config.py to "cuda"
python train.py
```


## Project Structure

```

â”œâ”€â”€ train.py                  # Main training loop
â”œâ”€â”€ render.py                 # Rendering script to validate outputs; confirms forward pass correctness

â”œâ”€â”€ config.py                 # Configuration and training parameters

â”œâ”€â”€ forward.py                # 3DGS: Forward pass (reimplementation of graphdeco-inria/gaussian-splatting)
â”œâ”€â”€ backward.py               # 3DGS: Backward pass (reimplementation of graphdeco-inria/gaussian-splatting)
â”œâ”€â”€ loss.py                   # Loss functions for training (includes depth loss, though unused in this repo)
â”œâ”€â”€ scheduler.py              # Learning rate scheduler

â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ camera_utils.py       # Load camera intrinsics and extrinsics from training data
â”‚   â”œâ”€â”€ point_cloud_utils.py  # Point cloud I/O utilities (e.g., saving to .ply)
â”‚   â”œâ”€â”€ math_utils.py         # General math utilities (e.g., transformation matrices)
â”‚   â””â”€â”€ wp_utils.py           # Warp utilities for math operations and device transfer

â””â”€â”€ data/                     # Contains the NeRF-synthetic 'Lego' dataset

```

`forward.py` and `backward.py` are based on [graphdeco-inria/gaussian-splatting](https://github.com/graphdeco-inria/gaussian-splatting). The original pure CUDA version is now reimplemented in Nvidia Warp, easy to understand, set up, and run.

Densification and pruning logic is based on [yzslab/gaussian-splatting-lightning](https://github.com/yzslab/gaussian-splatting-lightning), but restructured here with minimal data preparation and simplified training logic.

## TODO

- Improve performance: This implementation focuses on correctness and clarity over speed; there's room for Warp kernel optimization.
- Filter inactive points â€” The saved .ply files include many points that do not contribute to rendering. A better pruning strategy or visibility check is needed.